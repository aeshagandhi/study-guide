# ğŸ§  IDS 702 Midterm Comprehensive Study Guide

---

## ğŸ“ Unit 1: Statistics Fundamentals

### 1ï¸âƒ£ Population vs. Sample
- **Population**: entire group of interest.  
- **Sample**: subset used to estimate population parameters.  
- **Goal**: draw *inferences* about the population using the sample.  
- Sampling introduces **sampling variability** â€” results change with different samples.

---

### 2ï¸âƒ£ Inference vs. Prediction
| Type | Goal | Example |
|------|------|----------|
| **Inference** | Explain relationships / test hypotheses | Does smoking affect heart disease risk? |
| **Prediction** | Forecast outcomes | Predict next yearâ€™s COâ‚‚ emissions |

---

### 3ï¸âƒ£ Probability Concepts
- **Random variable (RV)**: numerical outcome of a random event.  
- **PMF/PDF**: functions giving probability (discrete) or density (continuous).  
- **Expected value (E[X])**: long-run average outcome.  
- **Variance (Var[X])**: spread around the mean.  
- **Joint probability**: Pr(A âˆ§ B)  
- **Conditional probability**: Pr(A | B) = Pr(A âˆ§ B)/Pr(B)  
- **Mutual exclusivity** â‡’ Pr(A âˆ§ B)=0.

---

### 4ï¸âƒ£ Common Distributions
- **Binomial** â†’ # of successes in n independent Bernoulli trials.  
- **Normal** â†’ continuous symmetric â€œbellâ€ curve; defined by Î¼, ÏƒÂ².  
- **Approximation**: for large n, Binomial â‰ˆ Normal(Î¼ = np, ÏƒÂ² = np(1 âˆ’ p)).

---

### 5ï¸âƒ£ Sampling Distributions & CLT
- **Sampling distribution**: distribution of a statistic (e.g., sample mean) over many samples.  
- **Central Limit Theorem (CLT)**: regardless of the populationâ€™s shape,  
  \[
  \bar{X} \sim N(\mu, \sigma^2/n)
  \]
  for large n.  
- **Standard deviation** vs. **standard error (SE)**:
  - SD = spread of individual data.
  - SE = spread of sample statistic (decreases âˆ 1/âˆšn).

---

### 6ï¸âƒ£ Maximum Likelihood Estimation (MLE)
1. Write the **likelihood** L(Î¸)=P(data | Î¸).  
2. Take log â†’ log-likelihood.  
3. Differentiate w.r.t Î¸, set = 0 â†’ solve Î¸Ì‚.  
4. MLE has good properties (consistency, asymptotic normality).

Intuition: choose parameter Î¸ that makes observed data most â€œlikely.â€

---

### 7ï¸âƒ£ Confidence Intervals (CI)
- **Interpretation**: If we repeatedly sampled, â‰ˆ 95 % of CIs would contain the true parameter.  
- **Affects width**: variability â†‘ â†’ CI wider; n â†‘ â†’ CI narrower; confidence â†‘ â†’ CI wider.  
- **Analytical** vs. **Bootstrap**:  
  - Analytical: use formulas & distribution assumptions.  
  - Bootstrap: resample data; compute empirical CI (no parametric assumption).

---

### 8ï¸âƒ£ Hypothesis Testing
1. **Form hypotheses** Hâ‚€ vs Hâ‚.  
2. **Compute test statistic** (t, z, Ï‡Â², F).  
3. **Find p-value** = Pr(statistic â‰¥ observed | Hâ‚€ true).  
4. **Decision rule**: p < Î± â†’ reject Hâ‚€.

**Types of tests**  
- *Parametric*: assume known distribution (t-test, z-test).  
- *Simulation-based*: permutation or bootstrap tests.  

**Two-sample logic**  
- Within-sample dependence â†’ paired test.  
- Across-sample independence â†’ independent-samples test.

---

## ğŸ“ Unit 2: Linear Regression

---

### 1ï¸âƒ£ Simple & Multiple Linear Regression

#### Model form
\[
y_i = \beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip} + \varepsilon_i
\]

#### Theoretical vs. Fitted
- *Theoretical model*: describes population relationship.  
- *Fitted model*: estimated from data via **OLS**.

#### Least Squares Idea
Minimize \( RSS = \sum (y_i - \hat{y_i})^2 \).  
OLS line minimizes squared residuals.

#### Interpretation
- **Î²Ì‚j** = expected change in y for one-unit change in xj, holding others constant.  
- **p-value(Î²Ì‚j)** â†’ evidence predictor â‰  0.  
- **CI(Î²Ì‚j)** â†’ range of plausible slope values.

---

### 2ï¸âƒ£ Matrix Notation
\[
\mathbf{Y}=X\boldsymbol{\beta}+\varepsilon
\]
- X = n Ã— p matrix (incl. intercept column of 1â€™s).  
- Î² = p Ã— 1 vector of parameters.  
- Îµ = n Ã— 1 vector of residuals.  
- OLS solution: Î²Ì‚ = (Xáµ€X)â»Â¹ Xáµ€Y.

---

### 3ï¸âƒ£ Categorical Predictors

- Convert factor with K levels â†’ K âˆ’ 1 dummy variables.  
- Choose a **reference (baseline)** category; coefficients compare each level to baseline.  
- **Interpretation:** Î²Ì‚j = difference in mean Y between that level and baseline, holding others constant.  
- Avoid including all K dummies â†’ *perfect multicollinearity*.

---

### 4ï¸âƒ£ Interaction Terms

Model:
\[
Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3(X_1X_2) + \varepsilon
\]
- The **interaction coefficient (Î²â‚ƒ)** shows how the effect of Xâ‚ changes across Xâ‚‚.  
- If Î²â‚ƒ â‰  0, the slope of Xâ‚ depends on Xâ‚‚.  
- *Use when*: theory or EDA suggests varying slopes by groups.

**Example**  
â€œEffect of dosage on anxiety differs by age group.â€

---

### 5ï¸âƒ£ Model Assessment

#### Coefficient of Determination (RÂ²)
\[
R^2 = 1 - \frac{RSS}{TSS}
\]
Proportion of variance explained by the model.

#### Adjusted RÂ²
Penalizes extra predictors:
\[
R^2_{adj} = 1 - (1 - R^2)\frac{n - 1}{n - p - 1}
\]

#### Interpreting RÂ²
- High RÂ² â‰  good model if assumptions fail.  
- Use adjusted RÂ² for comparing models with different p.

---

### 6ï¸âƒ£ Regression Assumptions

| Assumption | Diagnostic | Fix if Violated |
|-------------|-------------|----------------|
| **Linearity** | residuals vs fitted (no pattern) | add polynomial / log transform |
| **Independence** | residuals vs index (no trends) | change study design / use mixed model |
| **Normality** | Qâ€“Q plot (points â‰ˆ 45Â° line) | transform y or use robust inference |
| **Equal variance** | residuals vs fitted (no fan shape) | transform y or weighted least squares |

---

### 7ï¸âƒ£ F-Test (Overall Model)

Tests whether **all slopes = 0**:
\[
H_0: \beta_1=\beta_2=\dots=\beta_p=0
\]
\[
F = \frac{MSR}{MSE} = \frac{(SSR/(p))}{(SSE/(n-p-1))}
\]
If F large â†’ at least one predictor explains significant variance.

---

### 8ï¸âƒ£ Nested F-Test (Partial F-Test)

Compares **full vs. reduced model**.

\[
F = \frac{(RSS_R - RSS_F)/(p_F - p_R)}{RSS_F/(n - p_F)}
\]

**Interpretation:**
- \(H_0:\) extra predictors = 0  
- Reject Hâ‚€ â†’ added variables improve model fit.  
Used for sets of categorical dummy variables or interaction terms.

**In R:**  
```r
anova(reduced_model, full_model)
